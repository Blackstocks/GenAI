{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello World\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import json\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /opt/anaconda3/envs/openaidemo/lib/python3.10/site-packages (1.93.0)\n",
      "Requirement already satisfied: dotenv in /opt/anaconda3/envs/openaidemo/lib/python3.10/site-packages (0.9.9)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/envs/openaidemo/lib/python3.10/site-packages (2.3.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/anaconda3/envs/openaidemo/lib/python3.10/site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/anaconda3/envs/openaidemo/lib/python3.10/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/anaconda3/envs/openaidemo/lib/python3.10/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/anaconda3/envs/openaidemo/lib/python3.10/site-packages (from openai) (0.10.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/anaconda3/envs/openaidemo/lib/python3.10/site-packages (from openai) (2.11.7)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/envs/openaidemo/lib/python3.10/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /opt/anaconda3/envs/openaidemo/lib/python3.10/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /opt/anaconda3/envs/openaidemo/lib/python3.10/site-packages (from openai) (4.14.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/anaconda3/envs/openaidemo/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.3.0)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/anaconda3/envs/openaidemo/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/envs/openaidemo/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2025.6.15)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/envs/openaidemo/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/anaconda3/envs/openaidemo/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/envs/openaidemo/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /opt/anaconda3/envs/openaidemo/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/anaconda3/envs/openaidemo/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
      "Requirement already satisfied: python-dotenv in /opt/anaconda3/envs/openaidemo/lib/python3.10/site-packages (from dotenv) (1.1.1)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /opt/anaconda3/envs/openaidemo/lib/python3.10/site-packages (from pandas) (2.2.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/envs/openaidemo/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/envs/openaidemo/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/envs/openaidemo/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/openaidemo/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install openai dotenv pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: openai\n",
      "Version: 1.93.0\n",
      "Summary: The official Python library for the openai API\n",
      "Home-page: https://github.com/openai/openai-python\n",
      "Author: \n",
      "Author-email: OpenAI <support@openai.com>\n",
      "License: Apache-2.0\n",
      "Location: /opt/anaconda3/envs/openaidemo/lib/python3.10/site-packages\n",
      "Requires: anyio, distro, httpx, jiter, pydantic, sniffio, tqdm, typing-extensions\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "OPEN_API_KEY = os.getenv(\"OPEN_API_KEY\") \n",
    "print(OPEN_API_KEY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = OPEN_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /opt/anaconda3/envs/openaidemo/lib/python3.10/site-packages (1.93.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/anaconda3/envs/openaidemo/lib/python3.10/site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/anaconda3/envs/openaidemo/lib/python3.10/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/anaconda3/envs/openaidemo/lib/python3.10/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/anaconda3/envs/openaidemo/lib/python3.10/site-packages (from openai) (0.10.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/anaconda3/envs/openaidemo/lib/python3.10/site-packages (from openai) (2.11.7)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/envs/openaidemo/lib/python3.10/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /opt/anaconda3/envs/openaidemo/lib/python3.10/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /opt/anaconda3/envs/openaidemo/lib/python3.10/site-packages (from openai) (4.14.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/anaconda3/envs/openaidemo/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.3.0)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/anaconda3/envs/openaidemo/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/envs/openaidemo/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2025.6.15)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/envs/openaidemo/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/anaconda3/envs/openaidemo/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/envs/openaidemo/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /opt/anaconda3/envs/openaidemo/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/anaconda3/envs/openaidemo/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# checking the list of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(id='gpt-4-0613', created=1686588896, object='model', owned_by='openai')\n",
      "Model(id='gpt-4', created=1687882411, object='model', owned_by='openai')\n",
      "Model(id='gpt-3.5-turbo', created=1677610602, object='model', owned_by='openai')\n",
      "Model(id='o4-mini-deep-research-2025-06-26', created=1750866121, object='model', owned_by='system')\n",
      "Model(id='o3-pro-2025-06-10', created=1749166761, object='model', owned_by='system')\n",
      "Model(id='o4-mini-deep-research', created=1749685485, object='model', owned_by='system')\n",
      "Model(id='o3-deep-research', created=1749840121, object='model', owned_by='system')\n",
      "Model(id='o3-deep-research-2025-06-26', created=1750865219, object='model', owned_by='system')\n",
      "Model(id='davinci-002', created=1692634301, object='model', owned_by='system')\n",
      "Model(id='babbage-002', created=1692634615, object='model', owned_by='system')\n",
      "Model(id='gpt-3.5-turbo-instruct', created=1692901427, object='model', owned_by='system')\n",
      "Model(id='gpt-3.5-turbo-instruct-0914', created=1694122472, object='model', owned_by='system')\n",
      "Model(id='dall-e-3', created=1698785189, object='model', owned_by='system')\n",
      "Model(id='dall-e-2', created=1698798177, object='model', owned_by='system')\n",
      "Model(id='gpt-4-1106-preview', created=1698957206, object='model', owned_by='system')\n",
      "Model(id='gpt-3.5-turbo-1106', created=1698959748, object='model', owned_by='system')\n",
      "Model(id='tts-1-hd', created=1699046015, object='model', owned_by='system')\n",
      "Model(id='tts-1-1106', created=1699053241, object='model', owned_by='system')\n",
      "Model(id='tts-1-hd-1106', created=1699053533, object='model', owned_by='system')\n",
      "Model(id='text-embedding-3-small', created=1705948997, object='model', owned_by='system')\n",
      "Model(id='text-embedding-3-large', created=1705953180, object='model', owned_by='system')\n",
      "Model(id='gpt-4-0125-preview', created=1706037612, object='model', owned_by='system')\n",
      "Model(id='gpt-4-turbo-preview', created=1706037777, object='model', owned_by='system')\n",
      "Model(id='gpt-3.5-turbo-0125', created=1706048358, object='model', owned_by='system')\n",
      "Model(id='gpt-4-turbo', created=1712361441, object='model', owned_by='system')\n",
      "Model(id='gpt-4-turbo-2024-04-09', created=1712601677, object='model', owned_by='system')\n",
      "Model(id='gpt-4o', created=1715367049, object='model', owned_by='system')\n",
      "Model(id='gpt-4o-2024-05-13', created=1715368132, object='model', owned_by='system')\n",
      "Model(id='gpt-4o-mini-2024-07-18', created=1721172717, object='model', owned_by='system')\n",
      "Model(id='gpt-4o-mini', created=1721172741, object='model', owned_by='system')\n",
      "Model(id='gpt-4o-2024-08-06', created=1722814719, object='model', owned_by='system')\n",
      "Model(id='chatgpt-4o-latest', created=1723515131, object='model', owned_by='system')\n",
      "Model(id='o1-preview-2024-09-12', created=1725648865, object='model', owned_by='system')\n",
      "Model(id='o1-preview', created=1725648897, object='model', owned_by='system')\n",
      "Model(id='o1-mini-2024-09-12', created=1725648979, object='model', owned_by='system')\n",
      "Model(id='o1-mini', created=1725649008, object='model', owned_by='system')\n",
      "Model(id='gpt-4o-realtime-preview-2024-10-01', created=1727131766, object='model', owned_by='system')\n",
      "Model(id='gpt-4o-audio-preview-2024-10-01', created=1727389042, object='model', owned_by='system')\n",
      "Model(id='gpt-4o-audio-preview', created=1727460443, object='model', owned_by='system')\n",
      "Model(id='gpt-4o-realtime-preview', created=1727659998, object='model', owned_by='system')\n",
      "Model(id='omni-moderation-latest', created=1731689265, object='model', owned_by='system')\n",
      "Model(id='omni-moderation-2024-09-26', created=1732734466, object='model', owned_by='system')\n",
      "Model(id='gpt-4o-realtime-preview-2024-12-17', created=1733945430, object='model', owned_by='system')\n",
      "Model(id='gpt-4o-audio-preview-2024-12-17', created=1734034239, object='model', owned_by='system')\n",
      "Model(id='gpt-4o-mini-realtime-preview-2024-12-17', created=1734112601, object='model', owned_by='system')\n",
      "Model(id='gpt-4o-mini-audio-preview-2024-12-17', created=1734115920, object='model', owned_by='system')\n",
      "Model(id='o1-2024-12-17', created=1734326976, object='model', owned_by='system')\n",
      "Model(id='o1', created=1734375816, object='model', owned_by='system')\n",
      "Model(id='gpt-4o-mini-realtime-preview', created=1734387380, object='model', owned_by='system')\n",
      "Model(id='gpt-4o-mini-audio-preview', created=1734387424, object='model', owned_by='system')\n",
      "Model(id='o3-mini', created=1737146383, object='model', owned_by='system')\n",
      "Model(id='o3-mini-2025-01-31', created=1738010200, object='model', owned_by='system')\n",
      "Model(id='gpt-4o-2024-11-20', created=1739331543, object='model', owned_by='system')\n",
      "Model(id='gpt-4.5-preview', created=1740623059, object='model', owned_by='system')\n",
      "Model(id='gpt-4.5-preview-2025-02-27', created=1740623304, object='model', owned_by='system')\n",
      "Model(id='gpt-4o-search-preview-2025-03-11', created=1741388170, object='model', owned_by='system')\n",
      "Model(id='gpt-4o-search-preview', created=1741388720, object='model', owned_by='system')\n",
      "Model(id='gpt-4o-mini-search-preview-2025-03-11', created=1741390858, object='model', owned_by='system')\n",
      "Model(id='gpt-4o-mini-search-preview', created=1741391161, object='model', owned_by='system')\n",
      "Model(id='gpt-4o-transcribe', created=1742068463, object='model', owned_by='system')\n",
      "Model(id='gpt-4o-mini-transcribe', created=1742068596, object='model', owned_by='system')\n",
      "Model(id='o1-pro-2025-03-19', created=1742251504, object='model', owned_by='system')\n",
      "Model(id='o1-pro', created=1742251791, object='model', owned_by='system')\n",
      "Model(id='gpt-4o-mini-tts', created=1742403959, object='model', owned_by='system')\n",
      "Model(id='o3-2025-04-16', created=1744133301, object='model', owned_by='system')\n",
      "Model(id='o4-mini-2025-04-16', created=1744133506, object='model', owned_by='system')\n",
      "Model(id='o3', created=1744225308, object='model', owned_by='system')\n",
      "Model(id='o4-mini', created=1744225351, object='model', owned_by='system')\n",
      "Model(id='gpt-4.1-2025-04-14', created=1744315746, object='model', owned_by='system')\n",
      "Model(id='gpt-4.1', created=1744316542, object='model', owned_by='system')\n",
      "Model(id='gpt-4.1-mini-2025-04-14', created=1744317547, object='model', owned_by='system')\n",
      "Model(id='gpt-4.1-mini', created=1744318173, object='model', owned_by='system')\n",
      "Model(id='gpt-4.1-nano-2025-04-14', created=1744321025, object='model', owned_by='system')\n",
      "Model(id='gpt-4.1-nano', created=1744321707, object='model', owned_by='system')\n",
      "Model(id='gpt-image-1', created=1745517030, object='model', owned_by='system')\n",
      "Model(id='codex-mini-latest', created=1746673257, object='model', owned_by='system')\n",
      "Model(id='o3-pro', created=1748475349, object='model', owned_by='system')\n",
      "Model(id='gpt-4o-realtime-preview-2025-06-03', created=1748907838, object='model', owned_by='system')\n",
      "Model(id='gpt-4o-audio-preview-2025-06-03', created=1748908498, object='model', owned_by='system')\n",
      "Model(id='gpt-3.5-turbo-16k', created=1683758102, object='model', owned_by='openai-internal')\n",
      "Model(id='tts-1', created=1681940951, object='model', owned_by='openai-internal')\n",
      "Model(id='whisper-1', created=1677532384, object='model', owned_by='openai-internal')\n",
      "Model(id='text-embedding-ada-002', created=1671217299, object='model', owned_by='openai-internal')\n"
     ]
    }
   ],
   "source": [
    "# checking the list of models\n",
    "client = openai.OpenAI(api_key=OPEN_API_KEY)\n",
    "models = client.models.list()\n",
    "for model in models.data:\n",
    "    print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chat Completion and completion API\n",
    "\n",
    "Chat Completion API -> Nails it in chat game keeping the conversation flow intact, takes multiple prompt\n",
    "Completion API -> Hooks you up with text completions from a single prompt, takes one prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, a gentle unicorn named Luna\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI(api_key=OPEN_API_KEY) \n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4.1-nano\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Write a one-sentence bedtime story about a unicorn.\"}],\n",
    "    max_tokens=10, # max number of tokens to generate\n",
    "    temperature=0.7, # controls randomness of the output. if its near to 0 then it will be more deterministic and if its near to 1 then it will be more random\n",
    "    #n = 2 # number of responses to generate\n",
    ")\n",
    "print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! Here's a story about Tony Stark:\n",
      "\n",
      "---\n",
      "\n",
      "**Tony Stark: The Man Behind the Iron**\n",
      "\n",
      "Once upon a time in\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "prompt = \"Write a story on tonny stark.\"\n",
    "client = OpenAI(api_key=OPEN_API_KEY) \n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4.1-nano\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are not helpful assistant that can answer questions and help with tasks.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ],\n",
    "    max_tokens=25, # max number of tokens to generate\n",
    "    temperature=0.7, # controls randomness of the output. if its near to 0 then it will be more deterministic and if its near to 1 then it will be more random\n",
    "    #n = 2 # number of responses to generate\n",
    ")\n",
    "print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "टोनी स्टार्क पर एक कहानी लिखें।\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "prompt = \"translate in hindi: Write a story on tonny stark.\"\n",
    "client = OpenAI(api_key=OPEN_API_KEY) \n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4.1-nano\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant that can answer questions and help with tasks.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ],\n",
    "    max_tokens=25, # max number of tokens to generate\n",
    "    temperature=0.7, # controls randomness of the output. if its near to 0 then it will be more deterministic and if its near to 1 then it will be more random\n",
    "    #n = 2 # number of responses to generate\n",
    ")\n",
    "print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the weather of a perticular location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting requests\n",
      "  Using cached requests-2.32.4-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests)\n",
      "  Downloading charset_normalizer-3.4.2-cp310-cp310-macosx_10_9_universal2.whl.metadata (35 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/openaidemo/lib/python3.10/site-packages (from requests) (3.10)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests)\n",
      "  Downloading urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/openaidemo/lib/python3.10/site-packages (from requests) (2025.6.15)\n",
      "Using cached requests-2.32.4-py3-none-any.whl (64 kB)\n",
      "Downloading charset_normalizer-3.4.2-cp310-cp310-macosx_10_9_universal2.whl (201 kB)\n",
      "Downloading urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Installing collected packages: urllib3, charset_normalizer, requests\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [requests]\n",
      "\u001b[1A\u001b[2KSuccessfully installed charset_normalizer-3.4.2 requests-2.32.4 urllib3-2.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from datetime import date\n",
    "\n",
    "def get_weather(location):\n",
    "    find_url = \"https://ai-weather-by-meteosource.p.rapidapi.com/find_places\"\n",
    "    find_params = {\"text\": location, \"language\": \"en\"}\n",
    "    headers = {\n",
    "        \"x-rapidapi-key\": \"cd63083a33msha2e5829aa1a8e78p183c42jsn92196e6a83c6\",\n",
    "        \"x-rapidapi-host\": \"ai-weather-by-meteosource.p.rapidapi.com\"\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        find_response = requests.get(find_url, headers=headers, params=find_params)\n",
    "        find_response.raise_for_status()\n",
    "        places_data = find_response.json()\n",
    "        \n",
    "        if not places_data or len(places_data) == 0:\n",
    "            return {\"error\": f\"Location '{location}' not found\"}\n",
    "        place = places_data[0]\n",
    "        place_id = place.get('place_id')\n",
    "        \n",
    "        if not place_id:\n",
    "            return {\"error\": \"Could not get place ID for location\"}\n",
    "        \n",
    "        weather_url = \"https://ai-weather-by-meteosource.p.rapidapi.com/current\"\n",
    "        weather_params = {\"place_id\": place_id, \"timezone\": \"auto\", \"language\": \"en\", \"units\": \"auto\"}\n",
    "        \n",
    "        weather_response = requests.get(weather_url, headers=headers, params=weather_params)\n",
    "        weather_response.raise_for_status()\n",
    "        weather_data = weather_response.json()\n",
    "        \n",
    "        current = weather_data.get('current', {})\n",
    "        return {\n",
    "            \"location\": location,\n",
    "            \"temperature\": current.get('temperature'),\n",
    "            \"feels_like\": current.get('feels_like'),\n",
    "            \"humidity\": current.get('humidity'),\n",
    "            \"wind_speed\": current.get('wind', {}).get('speed'),\n",
    "            \"weather_summary\": current.get('summary'),\n",
    "            \"icon\": current.get('icon')\n",
    "        }\n",
    "        \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return {\"error\": f\"Failed to fetch weather data: {str(e)}\"}\n",
    "    except json.JSONDecodeError as e:\n",
    "        return {\"error\": f\"Invalid response format: {str(e)}\"}\n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"Unexpected error: {str(e)}\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'location': 'Delhi',\n",
       " 'temperature': 30.5,\n",
       " 'feels_like': 33.5,\n",
       " 'humidity': 36,\n",
       " 'wind_speed': 3.4,\n",
       " 'weather_summary': 'Mostly cloudy',\n",
       " 'icon': 'mostly_cloudy'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_weather(\"Delhi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\", \n",
    "        \"function\": {        \n",
    "            \"name\": \"get_weather\",\n",
    "            \"description\": \"Determine weather in my location\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The city and state e.g. San Francisco, CA\"\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"location\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using chat completion\n",
    "user_message = \"Hi There\"\n",
    "messages = []\n",
    "messages.append({\"role\":\"user\",\"content\":user_message})\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4.1-nano\",\n",
    "    messages=messages,\n",
    "    max_tokens=25,\n",
    "    temperature=0.7,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_message = \"What is the temparature of Delhi\"\n",
    "messages.append({\"role\":\"user\",\"content\":user_message})\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4.1-nano\",\n",
    "    messages=messages,\n",
    "    max_tokens=25,\n",
    "    temperature=0.7,\n",
    "    tools=tools,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ChatCompletionMessageToolCall(id='call_Ak41bIpbNQrR8fDmOLwOVfDq', function=Function(arguments='{\"\": null}', name='get_weather'), type='function')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user', 'content': 'Hi There'},\n",
       " {'role': 'user', 'content': 'What is the temparature of Delhi'}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'location'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m function_args \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(tool_call\u001b[38;5;241m.\u001b[39mfunction\u001b[38;5;241m.\u001b[39marguments)  \u001b[38;5;66;03m# This gives you {\"location\":\"Mumbai\"}\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Call your actual weather function\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m weather_result \u001b[38;5;241m=\u001b[39m get_weather(\u001b[43mfunction_args\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlocation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m)  \u001b[38;5;66;03m# Calls get_weather(\"Mumbai\")\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Add AI's function call request\u001b[39;00m\n\u001b[1;32m      8\u001b[0m messages\u001b[38;5;241m.\u001b[39mappend(response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'location'"
     ]
    }
   ],
   "source": [
    "tool_call = response.choices[0].message.tool_calls[0]\n",
    "function_args = json.loads(tool_call.function.arguments)  # This gives you {\"location\":\"Mumbai\"}\n",
    "\n",
    "# Call your actual weather function\n",
    "weather_result = get_weather(function_args[\"location\"])  # Calls get_weather(\"Mumbai\")\n",
    "\n",
    "# Add AI's function call request\n",
    "messages.append(response.choices[0].message)\n",
    "\n",
    "# Add function result\n",
    "messages.append({\n",
    "    \"role\": \"tool\",\n",
    "    \"tool_call_id\": tool_call.id,\n",
    "    \"content\": str(weather_result)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current temperature in Mumbai is approximately 32°C.  \n",
      "The current temperature in Delhi is approximately 35°C.  \n",
      "\n",
      "Please note that these temperatures are approximate and may vary slightly.\n"
     ]
    }
   ],
   "source": [
    "# Make another API call to get the final response\n",
    "final_response = client.chat.completions.create(\n",
    "    model=\"gpt-4.1-nano\",\n",
    "    messages=messages,\n",
    "    max_tokens=150,\n",
    "    temperature=0.7,\n",
    ")\n",
    "\n",
    "print(final_response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openaidemo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
